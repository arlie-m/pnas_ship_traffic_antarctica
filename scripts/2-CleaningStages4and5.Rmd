---
title: "2 - Cleaning and QC Stages 4 and 5"
author: "Arlie McCarthy"
date: "21/11/2019"
output: 
  github_document: default
  html_document: default
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "workflow") })
---
```{r setup, message=FALSE, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(tidyverse)
library(trip)
library(mapdata)
library(sf)
library(maptools)
library(janitor)
library(cowplot)
library(lubridate)
library(here)
```
## Summary

This script performs stages 4 and 5 of the cleaning process and generates 'main' files for use in later analyses. This includes:

  a) removing duplicate sightings and port calls
  b) removing any sightings on land
  c) creating the 'trips'
  d) using a speedfilter to further remove any unsuitable sightings based on speed. 
  
Some of the date/times from port calls were automatically generated by Informa's database because it requires both arrival and sailed times but they were not always available in the information received by Informa. In these cases a qualifier was added to indicate that it was generated by the system, usually the time is listed as "before" or "after" the next or previous time. The speedfilter needs to be run excluding those times because they frequently indicate that the ship was in two places at once, but they are not removed from the main file because the port calls are still important for the network. 

Aspecrts of this script could certianly have been written more succintly effeciently, but it runs and doesn't need to be re-run for any downstream analysis so I will leave it as.

I often subset groups that are not in a list so I create a handy little function to be the opposite of `%in%`. 
```{r}
`%!in%` <- Negate(`%in%`)
```

## Import master files
The master files generated in the first script are imported. These are the ones to be used in this script.

```{r IMPORT MASTER FILES, message=FALSE}
# list of vessels
vessels_master <- read_csv(here("data", "vessels_master.csv"))
# list of southern ocean observations
sightings_master <- read_csv(here("data", "sightings_master.csv"),
  col_types = cols(date_time = col_datetime(format = "%Y-%m-%d %H:%M:%S"))
)
# list of port calls
movements_master <- read_csv(here("data", "movements_master.csv"),
  col_types = cols(
    arrival_date = col_datetime(format = "%Y-%m-%d %H:%M:%S"),
    sailed_date = col_datetime(format = "%Y-%m-%d %H:%M:%S")
  )
)
# list of ports
port_locations_master <- read_csv(here("data", "port_locations_master.csv"),
  col_types = cols(
    movement_type = col_character(),
    notes = col_character(), source = col_character()
  )
)
```

## Checking for sightings on land and removing them
Desipte the QC already done, there are likely to be some ship sightings in the Southern Ocean that are on land. To check this,  I plot the sightings over a map of Antarctica.
Here I use map_data because it is a low res version that loads faster, this is used to check if there are still some obviously incorrect ship observations on land that need filtering, but a high resolution coastline is used to actually filter the points.

```{r ROUGHMAP}
world <- map_data("world")
# subset world to just include antarctic coastline
continents <- map_data("world", region = "antarctica")
# create a ggplot map to use as the base map for adding points to
figbase <- ggplot() +
  geom_polygon(
    data = continents,
    mapping = aes(x = long, y = lat, group = group),
    fill = "lightgrey"
  ) +
  theme_light() +
  coord_map("ortho", orientation = c(-90, 0, 0), ylim = c(-90, -60))
```

For plotting, I create a `sf` object of the sightings, then plot it with the base map (figbase) created above. There are duplicates because of the way the data were generated, removed in the following. Coordinate variables are duplicated because it is convenient to have them as a normal variable in addition to geometry when it is converted to a sf object.

```{r CREATING SF SIGHTINGS OBJECT}
sightings_sf <- sightings_master %>%
  mutate(lat_2 = latitude, lon_2 = longitude) %>%
  group_by(vessel_id, date_time) %>%
  distinct() %>%
  ungroup()

sightings_sf <- st_as_sf(sightings_sf,
  coords = c("lon_2", "lat_2"),
  crs = 4326
)
sightings_sf <- sf::st_transform(sightings_sf, crs = 3031)

roughmap <- figbase +
  geom_point(
    data = as_tibble(sightings_sf),
    mapping = aes(x = longitude, y = latitude)
  )
roughmap
```

As expected, some sightings are on land and they need to be removed. The following chunk uses a high resolution polygon (map) of Antarctica. This high resolution coastline of Antarctica was downloaded from the publicly available Antarctic Digital Database, curated by the British Antarctic Survey: https://add.data.bas.ac.uk/repository/entry/show?entryid=f477219b-9121-44d6-afa6-d8552762dc45 and downloaded on 30 August 2019. The files are not included in the GitHub repository because they are too large. Anyone running the next chunk of code will need to make sure they have downloaded the files and saved them in the relevant directory first. 

```{r REMOVING SIGHTINGS ON LAND}
antarctica <- st_read(here(
  "data", "Ant_coastline_high_res",
  "Coastline_high_res_polygon_v7.1.shp"
))
# I check the crs of the Antarctic coastline to make sure that I
# use the same crs for the map and ship sightings (3031)
st_crs(antarctica)
st_crs(sightings_sf)
# Because I want to identify the points to be removed I join the two object,
# which gives adds a variable (surface) that tells me whether each point
# overlaps with a given part of Antarctica or ice
sightings_sf <- st_join(sightings_sf, antarctica, left = TRUE)
# I create a new ovbject without the sightings on land, but I have kept the
# sightings that overlap with ice because the ice can change
sightings <- sightings_sf %>%
  filter(surface %in%
    c(NA, "ice shelf", "ice tongue", "rumple")) %>%
  clean_names()
```

We started with 373437 sightings, 794 of which are removed because they overlap with land, leaving 372643 sightings. I save the sightings dataframe, just in case it's useful later and remove everything needed to get this far, but not needed in subsequent sections.

```{r SAVE sightings_sf, eval=FALSE}
write.csv(sightings_sf,
  file = here("data", "sightings_sf.csv"), row.names = FALSE
)
# remove data frames that are no longer needed to tidy up global environment
rm(sightings_sf, antarctica, continents, sightings_master, roughmap)
```

## Running a speedfilter - cleaning stage 5
I will run a speedfilter using the 'trip' package to remove any points that would have required the ship to travel impossibly fast. I have set my threshold to 60km/hr because it is roughly the top cruising speed of the fastest vessel (a navy vessel) in my list of ships. The speed threshold was chosed by examining the ship secification information on fleetmon.com for 37 ships selected from all vessel types. The vessel with the fastest theoretical or observed top speed was HMS Sutherland, a UK navy vessel. The ship's maximum speed of 28kt plus a 10% buffer, gives a speed of 57.04km/hr, which was rounded up to 60km/hr to be a conservative threshold. Because of the high top speed I have selected, I will only remove impossible points for any ship, not based on each vessel type or the particular ships in my list. I am following the general principle of this QC process, which is to prefer false positives instead of false negatives, i.e. it is better to include some incorrect points/ships than exclude points/ships that are correct. 

### Preparing to create 'trip' objects
To be able to create a trip for each ship, I need to join the movements and sightings dataframes. 

To be able to join the movements to sightings, I need to create a movements dataframe with single datetimes for each location, but include whether it was an arrival or sailed date so that later on I can correctly recreate port stays for ships that revisit the same port over and over. In addition, because the speedfilter uses datetimes and location to calculate speed, I need to only use the port calls with datetimes that were not generated automatically by Informa's system, i.e. not indicating that a ship arrived or departed before or after a given time since this creates many instances where a ship appeared to be in two places at once. 

The following creates two dataframes, one for arrival datetimes and one for sailing datetimes and then combines them into one dataframe where every row is a single observation of a single ship.

```{r CREATE SINGLE MOVEMENTS FILE}
movements_arrival <- movements_master %>%
  dplyr::select(
    vessel_id,
    arrival_date,
    everything(),
    -sailed_date,
    -sailing_qualifier,
    -sailing_estimated,
    -movement_type_y
  ) %>%
  rename(
    date_time = arrival_date,
    estimated = arrival_estimated,
    qualifier = arrival_qualifier,
    movement_type = movement_type_x
  ) %>%
  add_column(port_stay = "arrival")

movements_sailed <- movements_master %>%
  dplyr::select(
    vessel_id,
    sailed_date,
    everything(),
    -arrival_date,
    -arrival_qualifier,
    -arrival_estimated,
    -movement_type_y
  ) %>%
  rename(
    date_time = sailed_date,
    estimated = sailing_estimated,
    qualifier = sailing_qualifier,
    movement_type = movement_type_x
  ) %>%
  add_column(port_stay = "sailed")

movements <- bind_rows(movements_arrival, movements_sailed)
rm(movements_arrival, movements_sailed)
```

The movements (port calls) are now ready to be combined with the sightings to create a single dataframe with all the observations of all ships that have passed QC so far. The combined location reads for all ships at this point is 435961 observations.

```{r CREATE all_obs}
all_obs <- bind_rows(movements, sightings) %>%
  rownames_to_column()
```

### Create trips and run the speed filter

Now for the trips! Before creating the trip, I filter out any location readings that are:  
a) missing coordinates or date/time stamps in case any have slipped through (sanity check), or  
b) have datetimes automatically estimated by Informa's system (from here on referred to as system-generated datetimes).

For the speedfilter to work, there also needs to be at least 3 observations for each ship, so I also remove and vessels with fewer than 3 observations. I also check how many unique vessels remain, in case any have been removed up to this point. 

```{r FILTERING OUT MISSING DATA}
trips <- all_obs %>%
  filter(!is.na(longitude)) %>%
  filter(!is.na(latitude)) %>%
  filter(!is.na(date_time)) %>%
  mutate(remove = case_when(
    qualifier %in% c("B", "A", "T") ~ TRUE,
    TRUE ~ FALSE
  )) %>%
  filter(remove == FALSE) %>%
  arrange(vessel_id, date_time) %>%
  group_by(vessel_id) %>%
  filter(n() > 3)

length(unique(trips$vessel_id))
```

By this stage have 258 ships in total (down from 266 in the vessels_master dataframe generated after the first 3 stages of cleaning), and down to 440837 observations of all ships. 50 were removed because they had missing date-time or coordinate information. The rest were removed because they were system-generated (estimated) date-times for port calls.

Now to actually create the trips and run the speed filter itself. It identifies those points where a ships would have needed to travel faster than my threshold, and I remove them.

```{r CREATING AND IMPLEMENTING THE SPEED FILTER}
trips_sf <- st_as_sf(trips,
  coords = c("longitude", "latitude"),
  crs = "+proj=longlat +datum=WGS84 +no_defs"
)

# Just in case, I add 1 second to any observations of a given ship
# that have the same date_time as the previous read. It prevents a
# ship being in two places at once, but also is not a large enough
# increment to prevent the speedfilter from removing points.
trips_sf$tms <- adjust.duplicateTimes(
  trips_sf$date_time,
  trips_sf$vessel_id
)

# Now I create a separate 'trip' object for each ship, using the tms
# not date_time variable
trips_tg <- trip(trips_sf, c("tms", "vessel_id"))
# And I run the speedfilter and add it as a variable in the dataframe
trips_speedfilter <- speedfilter(trips_tg, max.speed = 60)
trips_tg$speedfilter <- trips_speedfilter
```

Great! Now that I have run the speedfilter, I turn the trip object into a number of dataframes (tibbles) so that I can check what the speedfilter did and make sure I am happy with it.
```{r CREATING OBJECTS FOR CHECKING THE SPEEDFILTER}
# A tibble not 'trip' with all the observations and a TRUE/FALSE
# for whether the observations passed the speedfilter
trips_check <- as_tibble(trips_tg)

# A 'trip' object with only the observations that passed the
# speedfilter and should be kept
trips_keep <- subset(trips_tg, speedfilter == "TRUE" | !is.na(port_stay))
length(unique(trips_keep$vessel_id))
```

Results from initial speedfilter. There are still 258 unique vessels that should be kept. Now at 314274 observations down from 440837 (i.e. 126433 observations removed - not really much different from the 121946 removed with a 90km/hr limit). 

Now, before I take the next step and run them iteratively, I also want to remove any ships that no longer have sightings in the southern ocean. 

```{r}
vessels_s_o <- as_tibble(trips_keep) %>%
  filter(Y < -59) %>%
  group_by(vessel_id)

vessels_no_s_o <- anti_join(as_tibble(trips_keep), vessels_s_o, by = "vessel_id")
length(unique(vessels_no_s_o$vessel_id))
unique(vessels_no_s_o$vessel_id)
```
3 ships no longer have observations in the southern ocean so will need to be removed before the next round of filters. They are: 288272, 11145194, 12600246

```{r SECOND SPEEDFILTER PASS}
trips_keep_2 <- subset(trips_keep, vessel_id %!in% c(288272, 11145194, 12600246))
# Run the speedfilter again on those points that I have retained
trips_speedfilter_2 <- speedfilter(trips_keep_2, max.speed = 60)
trips_keep_2$speedfilter_2 <- trips_speedfilter_2
trips_keep_check_2 <- as_tibble(trips_keep_2)
# Remove any more points that need removing.
trips_keep_2 <- subset(trips_keep_2, speedfilter_2 == "TRUE" | !is.na(port_stay))
length(unique(trips_keep_2$vessel_id))
```

After the second pass of the speedfilter, there are 313904 observations of 255 ships. Now I check and remove any more ships with no SO observations.

```{r}
vessels_s_o <- as_tibble(trips_keep_2) %>%
  filter(Y < -59) %>%
  group_by(vessel_id)

vessels_no_s_o <- anti_join(as_tibble(trips_keep_2), vessels_s_o, by = "vessel_id")
length(unique(vessels_no_s_o$vessel_id))
unique(vessels_no_s_o$vessel_id)
```

Two more ships no longer have SO observations. They are: 286795, 309184

```{r SPEEDFILTER THIRD PASS}
trips_keep_3 <- subset(trips_keep_2, vessel_id %!in% c(286795, 309184))
# Run the speedfilter again on those points that I have retained
trips_speedfilter_3 <- speedfilter(trips_keep_3, max.speed = 60)
trips_keep_3$speedfilter_3 <- trips_speedfilter_3
trips_keep_check_3 <- as_tibble(trips_keep_3)
# Do it again with fewer points
trips_keep_3 <- subset(trips_keep_3, speedfilter_3 == "TRUE" | !is.na(port_stay))
length(unique(trips_keep_3$vessel_id))
```

Now there are 313665 observations of 253 ships remaining. Again remove any ships with no SO sightings.

```{r}
vessels_s_o <- as_tibble(trips_keep_3) %>%
  filter(Y < -59) %>%
  group_by(vessel_id)

vessels_no_s_o <- anti_join(as_tibble(trips_keep_3), vessels_s_o, by = "vessel_id")
length(unique(vessels_no_s_o$vessel_id))
unique(vessels_no_s_o$vessel_id)
```

No ships need to be removed because they have no SO sightings! 

```{r SPEEDFILTER FOURTH PASS}
trips_keep_4 <- trips_keep_3 # no need to subset but want a new, renamed object to be consistent
# Run the speedfilter again on those points that I have retained
trips_speedfilter_4 <- speedfilter(trips_keep_4, max.speed = 60)
trips_keep_4$speedfilter_4 <- trips_speedfilter_4
trips_keep_check_4 <- as_tibble(trips_keep_4)
# Do it again with fewer points again
trips_keep_4 <- subset(trips_keep_4, speedfilter_4 == "TRUE" | !is.na(port_stay))
length(unique(trips_keep_4$vessel_id))

vessels_s_o <- as_tibble(trips_keep_4) %>%
  filter(Y < -59) %>%
  group_by(vessel_id)

vessels_no_s_o <- anti_join(as_tibble(trips_keep_4), vessels_s_o, by = "vessel_id")
length(unique(vessels_no_s_o$vessel_id))
unique(vessels_no_s_o$vessel_id)
```

Now there are 313663 observations of 253 vessels, i.e. two observations removed, and no vessels need to be removed from the list due to no longer having observations in the Southern Ocean. 

```{r}
trips_keep_5 <- trips_keep_4 # no need to subset but want a new, renamed object to be consistent
# Run the speedfilter again on those points that I have retained
trips_speedfilter_5 <- speedfilter(trips_keep_5, max.speed = 60)
trips_keep_5$speedfilter_5 <- trips_speedfilter_5
trips_keep_check_5 <- as_tibble(trips_keep_5)

trips_keep_5 <- subset(trips_keep_5, speedfilter_5 == "TRUE" | !is.na(port_stay))
length(unique(trips_keep_5$vessel_id))
```

Now there are 313662 observations of 253 ships. 

```{r}
trips_keep_6 <- trips_keep_5
# Run the speedfilter again on those points that I have retained
trips_speedfilter_6 <- speedfilter(trips_keep_6, max.speed = 60)
trips_keep_6$speedfilter_6 <- trips_speedfilter_6

trips_keep_6 <- subset(trips_keep_6, speedfilter_6 == "TRUE" | !is.na(port_stay))
trips_keep_check_6 <- as_tibble(trips_keep_6)
length(unique(trips_keep_6$vessel_id))
```

Now 313660 observations of 253 vessels.

```{r}
trips_keep_7 <- trips_keep_6
# Run the speedfilter again (7th time) on those points that I have retained
trips_speedfilter_7 <- speedfilter(trips_keep_6, max.speed = 60)
trips_keep_7$speedfilter_7 <- trips_speedfilter_7
trips_keep_check_7 <- as_tibble(trips_keep_7)

trips_keep_7 <- subset(trips_keep_7, speedfilter_7 == "TRUE" | !is.na(port_stay))
trips_keep_check_7 <- as_tibble(trips_keep_7)
length(unique(trips_keep_7$vessel_id))
```

313659 observations of 252 ships.

```{r}
# Run the speedfilter again (7th time) on those points that I have retained
trips_keep_8 <- trips_keep_7
trips_speedfilter_8 <- speedfilter(trips_keep_8, max.speed = 60)
trips_keep_8$speedfilter_8 <- trips_speedfilter_8
trips_keep_check_8 <- as_tibble(trips_keep_8)

trips_keep_8 <- subset(trips_keep_8, speedfilter == "TRUE" | !is.na(port_stay))
trips_keep_check_8 <- as_tibble(trips_keep_8)
length(unique(trips_keep_8$vessel_id))
# An object with only observations that did NOT pass the speedfilter
# and should be removed. This is a spatial points data frame object of
# that is automatically converted from 'trip' object because there are
# so few points per ship. Object type for this object is not important.
trips_remove <- anti_join(trips_check, trips_keep_check_8) %>%
  mutate(removed = TRUE)
trips_keep_final <- trips_keep_check_8 %>%
  mutate(removed = FALSE) %>%
  dplyr::select(-starts_with("speedfilter"))
length(unique(trips_remove$vessel_id))
```

165 ships have points removed by the speedfilter. I'd like to check which ships and points have been affected and make sure it is doing with I think it should be.

For the dataframe with the points that pass the filter (trips_keep_check_8), there are 253 ships and 3136759 observations (127187) observations removed). Since 29% of the observations were removed I'd like to run a few checks on it.

### Speedfilter Sanity check
This section is really to take a closer look at what is going on when I run the speedfilter and make sure I am happy that it is doing what I want it to. 

164 of the 257 ships are affected by the speed filter, but which ships are they? Are they all from the second set of ships provided or also the first? This distinction is important because the sightings were generated by Informa using slightly different methods and I may need to interpret the speedfilter results slightly differently. Also, to what extent is each ship affected?

```{r SET-UP FILES FOR SPEEDFILTER CHECK}
trips_all <- bind_rows(trips_remove, trips_keep_final)

# I import the list of vessels from the 2nd set of data, which
# I can use to distinguish between observations for the first
# and second set of ships.
vessels_2nd_verified <-
  read_csv(here("data", "additional_vessels_verified.csv"),
    col_types = cols(
      `#Positions reported South 60` = col_skip(),
      `Month/Year` = col_skip(), X1 = col_skip()
    )
  ) %>%
  clean_names()

speedfilter_1st_vessels <- trips_all %>%
  anti_join(vessels_2nd_verified, by = "vessel_id")
speedfilter_1st_vessels %>%
  filter(removed == TRUE) %>%
  count()
length(unique(speedfilter_1st_vessels$vessel_id))
# 2018 observations were removed with the speedfilter for 231 ships
# from the first set of data provided

speedfilter_2nd_vessels <- trips_all %>%
  semi_join(vessels_2nd_verified, by = "vessel_id")
speedfilter_2nd_vessels %>%
  filter(removed == TRUE) %>%
  count()
length(unique(speedfilter_2nd_vessels$vessel_id))
# 125160 observations were removed with the speedfilter for 27 ships
# from the second set of data provided. The good news is that there were
# clearly many points removed for a small number of ships,
# rather than widespread problems.
```

Now, I want to visually check what the speedfilter has removed for the ships from the first set of data. I use intermediate objects with the same name to avoid overcluttering the global environment, but if not running the chunks in order then be careful that the intermediate object has the correct data. I create two sets maps on a ship by ship basis. The first shows only the Southern Ocean sightings (plotted over a map of Antarctica), the second shows a world map of all the observations. 

```{r LOOKING AT SPEEDFILTER FIRST VESSELS}
trips_speed_sf <- st_as_sf(speedfilter_1st_vessels,
  coords = c("X", "Y"), crs = 4326
)
trips_speed_sf <- sf::st_transform(trips_speed_sf, crs = 3031)

speedfilter_map <- figbase +
  geom_point(
    data = as_tibble(speedfilter_1st_vessels),
    mapping = aes(x = X, y = Y, color = removed)
  ) +
  facet_wrap(~vessel_id)

speedfilter_map_world <- ggplot() +
  geom_polygon(
    data = world,
    mapping = aes(x = long, y = lat, group = group),
    fill = "lightgrey"
  ) +
  theme_light() +
  geom_point(
    data = as_tibble(speedfilter_1st_vessels),
    mapping = aes(x = X, y = Y, color = removed)
  ) +
  facet_wrap(~vessel_id)
```

For convenience, I save that plots as large pdfs to take a closer look. It can take too long to load in the viewer, and not all the points are visible anyway. WARNING these are  large files and might take a while to save and open as pdfs.

```{r SAVE AS PDFS FIRST SET, eval = FALSE}
ggsave2(here("outputs", "speedfilter_map_Antarctica_1st_60kmh_2nd.pdf"),
  plot = speedfilter_map,
  width = 40,
  height = 60,
  units = "cm"
)

ggsave2(here("outputs", "speedfilter_map_world_1st_60kmh_2nd.pdf"),
  plot = speedfilter_map_world,
  width = 40,
  height = 60,
  units = "cm"
)
```

I can now remove some of the objects I no longer need. 

```{r REMOVE OBJECTS FIRST SET}
rm(
  trips_speed_sf,
  speedfilter_map,
  speedfilter_map_world,
  trips_keep_2,
  trips_keep_3,
  trips_keep_4,
  trips_keep_5,
  trips_keep_6,
  trips_keep_7,
  trips_keep_check_2,
  trips_keep_check_3,
  trips_keep_check_4,
  trips_keep_check_5,
  trips_keep_check_6,
  trips_keep_check_7,
  vessels_no_s_o,
  vessels_s_o
)
```

Now, I want to visually check what the speedfilter has removed for the 24 ships from the 2nd set of data. So I do the same again for the second set of vessels.

```{r LOOKING AT SPEEDFILTER SECOND VESSELS}
trips_speed_sf <- st_as_sf(speedfilter_2nd_vessels,
  coords = c("X", "Y"),
  crs = 4326
)
trips_speed_sf <- sf::st_transform(trips_speed_sf, crs = 3031)

speedfilter_map <- figbase +
  geom_point(
    data = as_tibble(speedfilter_2nd_vessels),
    mapping = aes(x = X, y = Y, color = removed)
  ) +
  facet_wrap(~vessel_id)

speedfilter_map_world <- ggplot() +
  geom_polygon(
    data = world,
    mapping = aes(x = long, y = lat, group = group),
    fill = "lightgrey"
  ) +
  theme_light() +
  geom_point(
    data = as_tibble(speedfilter_2nd_vessels),
    mapping = aes(x = X, y = Y, color = removed)
  ) +
  facet_wrap(~vessel_id)
```

For convenience, I save that plots as large pdfs to take a closer look. It can take too long to load in the viewer, and not all the points are visible anyway. WARNING these are  large files and might take a while to save and open as pdfs.

```{r SAVE AS PDFS SECOND SET, eval = FALSE}
ggsave2(here("outputs", "speedfilter_map_Antarctica_2nd_60kmh_2nd.pdf"),
  plot = speedfilter_map,
  width = 40,
  height = 60,
  units = "cm"
)

ggsave2(here("outputs", "speedfilter_map_world_2nd_60kmh_2nd.pdf"),
  plot = speedfilter_map_world,
  width = 40,
  height = 60,
  units = "cm"
)
```

I can now remove some of the objects I no longer need. 

```{r REMOVE OBJECTS SECOND SET}
rm(trips_speed_sf, speedfilter_map, speedfilter_map_world)
```

Because of the the many overlapping points it's not always obvious what has been removed, but it is clear that there are still some ships that seem to be false positives, i.e. didn't really visit the Southern Ocean. They will need a closer look. Some ships have loads of points removed but the overall track of the ship is still very detailed so there doesn't seem to be an issue removing those points.

Based on the maps created above some ships should be removed because they no longer have any sightings in the southern ocean. There are also quite a few ships that seem to only have 1-2 Southern Ocean sightings after the speedfilter is applied. These need a closer look, but first I want to add back in the observations with system-generated datetimes, and the ships with under 4 observations so that I can see all the data for each ship. These observations will be included in the main dataframe that is used in subsequent scripts anyway. 

## Creating a new file of observations, updated from the speedfilter

Now I need to create updated files of observations, ships and ports that reflect the results of the speedfilter. However, I also need to make sure I keep all the observations and port calls that have system-generated datetimes, because I couldn't use them in the speedfilter.

So we  have 253 ships, which means that the speedfilter has removed 12 ships. Down to 313659 observations, but more will be included once I add the system-generated times. 

```{r SYSTEM-GENERATED TIMES}
sys_gen_datetimes <- all_obs %>%
  mutate(remove = case_when(
    qualifier %in% c("B", "A", "T") ~ TRUE,
    TRUE ~ FALSE
  )) %>%
  filter(remove == TRUE) %>%
  arrange(vessel_id, date_time)

# Ships with fewer than 4 observations after observations with system-
# generated times or missing datetimes and/or coordinates were also
# removed. Need to add them back in with same criteria used to remove
# them originally
too_few_obs <- all_obs %>%
  filter(!is.na(longitude)) %>%
  filter(!is.na(latitude)) %>%
  filter(!is.na(date_time)) %>%
  mutate(remove = case_when(
    qualifier %in% c("B", "A", "T") ~ TRUE,
    TRUE ~ FALSE
  )) %>%
  filter(remove == FALSE) %>%
  arrange(vessel_id, date_time) %>%
  group_by(vessel_id) %>%
  filter(n() < 4)

too_few_obs$geometry <- NULL

length(unique(too_few_obs$vessel_id))
```

So 7 ships were removed because they had fewer than 3 observations. I'll include them in my main list because few observations is not in the criteria for exclusion, especially since they might have system generated port calls, which would mean that actually had more than 3 observations total.

Now that I have an object with the system-generated times I can join it to the speedfiltered observations. Since there should be no overlapping observations I can use a full join. I then use a filtering join on the vessel list and port list so that I am only including vessels and ports that are still in my list. 

```{r JOINING OBSERVATIONS}
trips_main <- full_join(as_tibble(trips_keep_final), sys_gen_datetimes) %>%
  arrange(vessel_id, date_time) %>%
  full_join(too_few_obs) %>%
  mutate(
    latitude = coalesce(Y, latitude),
    longitude = coalesce(X, longitude)
  ) %>%
  dplyr::select(
    vessel_id,
    vessel_name,
    longitude,
    latitude,
    place,
    tms,
    date_time,
    estimated,
    qualifier,
    movement_type,
    move_sequence,
    port_stay,
    country
  )

vessels_s_o <- trips_main %>%
  filter(latitude < -59) %>%
  group_by(vessel_id)

vessels_no_s_o <- anti_join(trips_main, vessels_s_o, by = "vessel_id")
length(unique(vessels_no_s_o$vessel_id))
unique(vessels_no_s_o$vessel_id)

trips_main <- trips_main %>%
  filter(vessel_id %!in% c(286795, 288272, 309184, 11145194, 12600246))

length(trips_main$vessel_id)
length(unique(trips_main$vessel_id))
```
Five vessels have no Southern Ocean sightings and are removed. They are: 286795, 288272, 309184, 11145194, 12600246

The joined list has 328176 observations and 260 ships. 

## Checking Vessels with 0-2 Southern Ocean observations

Now I make histogram with the trips_main dataframe and get a list of ships that have fewer than 3 (a sensible cut-off based on the histogram) observations from the Southern Ocean.

```{r HISTOGRAM}
trips_vessel_histogram <- trips_main %>%
  filter(latitude < -59) %>%
  group_by(vessel_id) %>%
  filter(n() < 50) %>%
  count()

ggplot(trips_vessel_histogram, aes(x = n)) +
  geom_histogram(binwidth = 1)
```

In trips_main there are 33 ships that have 1 or 2 sightings in the Southern Ocean. So I need to make a list of vessels that Now I need to generate a list of of ships that have 0-2 sightings in the Southern Ocean, so that I can plot them on maps and take a closer look.

```{r LIST OF SHIPS WITH 0-2 SIGHTINGS}
trips_vessels_check <- trips_main %>%
  filter(latitude < -59) %>%
  group_by(vessel_id) %>%
  filter(n() < 3)
print(unique(trips_vessels_check$vessel_id))

vessels_s_o <- trips_main %>%
  filter(latitude < -59) %>%
  group_by(vessel_id)

vessels_no_s_o <- anti_join(trips_main, vessels_s_o, by = "vessel_id")
length(unique(vessels_no_s_o$vessel_id))

vessels_check <- as_tibble(unique(
  c(unique(trips_vessels_check$vessel_id), unique(vessels_no_s_o$vessel_id))
)) %>%
  rename(vessel_id = value)
print(vessels_check$vessel_id)
```

Great! So, I have a list of 33 ships, now I need to make a dataframe and plot it like I did above - a large pdf for the Southern Ocean sightings and another for the whole world.

```{r VESSELS CHECK ANTARCTICA}
vessels_check_obs <- trips_main %>%
  semi_join(vessels_check, by = "vessel_id")

vessels_check_map_antarctica <- figbase +
  geom_point(
    data = vessels_check_obs,
    mapping = aes(x = longitude, y = latitude)
  ) +
  facet_wrap(~vessel_id)
# Similar to previous times I made maps, they're very large
# and easier to see as a pdf.
ggsave2(here("outputs", "vessels_check_map_antarctica.pdf"),
  plot = vessels_check_map_antarctica,
  width = 40,
  height = 60,
  units = "cm"
)
```

Now make a similar map, but showing the selected 35 ships across the whole world.

```{r VESSELS CHECK WORLD}
vessels_check_map_world <- ggplot() +
  geom_polygon(
    data = world,
    mapping = aes(x = long, y = lat, group = group),
    fill = "lightgrey"
  ) +
  theme_light() +
  geom_point(
    data = vessels_check_obs,
    mapping = aes(x = longitude, y = latitude)
  ) +
  facet_wrap(~vessel_id)

ggsave2(here("outputs", "vessels_check_map_world.pdf"),
  plot = vessels_check_map_world,
  width = 40,
  height = 60,
  units = "cm"
)
```

Now that I'm happy with the list of observations and the ships in it, I save the trips_main file, and update the dataframes of vessels and ports so that they only include ships and ports actually visited in my filtered data. 

Ships that no longer having sightings in the Southern Ocean after speedfilter, or no longer pass any of the other criteria for inclusion.
They are: 
225071, 353358, 361938, 12473954, 12591860

## Saving updated files

Before I can move on, I need to create and save updated files of observations, vessels and port locations. 

```{r REMOVING SHIPS}
ships_to_remove <- tibble(
  vessel_id = c(
    225071, 353358, 361938, 12473954, 12591860
  )
)
trips_main <- trips_main %>%
  mutate(remove = case_when(
    vessel_id %in% ships_to_remove$vessel_id ~ "y",
    TRUE ~ "n"
  )) %>%
  filter(remove != "y")
length(unique(trips_main$vessel_id))
```

Now I have specifically removed the extra ships, I have more accurate sightings of 255 vessels. Now I want to make sure that the updated lists of vessels and ports only reflect the observations that I have. All these main files will be saved for use in the next script.

```{r SAVING MAIN FILES}
write.csv(trips_main, file = here("data", "trips_main.csv"), row.names = FALSE)
vessels_main <- semi_join(vessels_master, trips_main, by = "vessel_id")
write.csv(vessels_main, file = here("data", "vessels_main.csv"), row.names = FALSE)
port_locations_main <- semi_join(port_locations_master, trips_main, by = "place")
write.csv(port_locations_main, file = here("data", "port_locations_main.csv"), row.names = FALSE)
```
